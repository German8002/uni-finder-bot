name: crawl-max

on:
  workflow_dispatch:
  schedule:
    - cron: '0 3 * * 6'  # weekly, Saturday 03:00 UTC

permissions:
  contents: write

concurrency:
  group: crawl-max
  cancel-in-progress: false

jobs:
  build_universities:
    name: Build universities (Wikipedia) with heartbeat
    runs-on: ubuntu-latest
    timeout-minutes: 420  # 7h hard limit to avoid auto-cancel

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: pip install -r requirements.txt

      - name: Build universities (Wikipedia) with heartbeat
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          set -e
          python -u scraper_max/scripts/build_universities.py &
          PID=$!
          while kill -0 "$PID" 2>/dev/null; do
            echo "[heartbeat] build_universities.py still running $(date -u +'%Y-%m-%dT%H:%M:%SZ')"
            sleep 60
          done
          wait "$PID"

      - name: Upload universities.csv artifact (backup)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: universities_csv
          path: scraper_max/out/universities.csv
          if-no-files-found: warn

      - name: Inspect CSV head (debug)
        run: |
          echo "--- CSV head ---"
          head -n 15 scraper_max/out/universities.csv || true
          echo "----------------"

      - name: Convert CSV -> data/universities.json
        run: |
          python tools/convert_universities_csv_to_json.py scraper_max/out/universities.csv data/universities.json

      - name: Show JSON stats
        run: |
          python - <<'PY'
          import json, pathlib
          p = pathlib.Path("data/universities.json")
          d = json.loads(p.read_text(encoding="utf-8")) if p.exists() else []
          print("JSON items:", len(d))
          print("Sample:", d[:3])
          PY

      - name: Commit updated CSV+JSON
        run: |
          set -e
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git add scraper_max/out/universities.csv data/universities.json || true
          git diff --staged --quiet && echo "No changes to commit" || git commit -m "data: update universities.csv + data/universities.json [skip ci]"
          git pull --rebase --autostash
          git push
