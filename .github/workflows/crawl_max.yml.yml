
name: Crawl (max) and publish

on:
  workflow_dispatch:
  schedule:
    - cron: "0 3 * * 1"   # каждый понедельник в 03:00 UTC

jobs:
  crawl:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install aiohttp beautifulsoup4 lxml requests

      - name: Build universities catalog (Wikipedia)
        run: |
          python scraper_max/scripts/build_universities.py

      - name: Crawl all sites and normalize
        env:
          SCRAPE_CONCURRENCY: "8"
          PAGES_PER_SITE: "100"
          MAX_SITES: "300"
        run: |
          python scraper_max/scripts/crawl_all.py

      - name: Commit updated data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/programs.json scraper_max/out/universities.csv
          git commit -m "data: refresh programs via crawler" || echo "No changes"
          git push
